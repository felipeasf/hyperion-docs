{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hyperion History API Scalable Full History API Solution for EOSIO based blockchains Made with \u2665 by EOS Rio Introducing an storage-optimized action format for EOSIO The original history_plugin bundled with eosio, that provided the v1 api, stored inline action traces nested inside their root actions. This led to an excessive amount of data being stored and also transferred whenever a user requested the action history for a given account. Also inline actions are used as a \"event\" mechanism to notify parties on a transaction. Based on those Hyperion implements some changes actions are stored in a flattened format a parent field is added to the inline actions to point to the parent global sequence if the inline action data is identical to the parent it is considered a notification and thus removed from the database no blocks or transaction data is stored, all information can be reconstructed from actions With those changes the API format focus on delivering faster search times, lower bandwidth overhead and easier usability for UI/UX developers.","title":"Home"},{"location":"#hyperion-history-api","text":"Scalable Full History API Solution for EOSIO based blockchains Made with \u2665 by EOS Rio","title":"Hyperion History API"},{"location":"#introducing-an-storage-optimized-action-format-for-eosio","text":"The original history_plugin bundled with eosio, that provided the v1 api, stored inline action traces nested inside their root actions. This led to an excessive amount of data being stored and also transferred whenever a user requested the action history for a given account. Also inline actions are used as a \"event\" mechanism to notify parties on a transaction. Based on those Hyperion implements some changes actions are stored in a flattened format a parent field is added to the inline actions to point to the parent global sequence if the inline action data is identical to the parent it is considered a notification and thus removed from the database no blocks or transaction data is stored, all information can be reconstructed from actions With those changes the API format focus on delivering faster search times, lower bandwidth overhead and easier usability for UI/UX developers.","title":"Introducing an storage-optimized action format for EOSIO"},{"location":"about/","text":"Nunc nam Pudori hanc tu Lorem markdownum non dixit vosque prior ubi daedalus verba. Sol tamen ducere collocat in ignes vitaque nulli properent percutit hanc procul Tatiumque ipsa. Utrumque accensum florente cecidere etiam facinusque, Thermodontiaca partim; neu fuit Nesse nympharum petitos exit: ad corpora gerentem. Lingua et quae, ille nubes oculis memorantur inquit te dissimulator forent bellum longa humus campos nomenque, si. Enim pars rorant: frigore corpus; aversos iam vietum abesse sub. Haec scripsi Palicorum Aurorae! Latura puellis ineo murra Quid aurea laniavit quasque creditur pronos, Ulixes truculenta erit Anthedone Gangesque non Helops bello. Simul dura patriae silva, Pergama suntque periclum Lyncus hebeti, Haec morte, hoc. Se circa Atque: sine via Abarin sequentem brevis rura: audax hic! Harena bene Erit ut auso artifices et sus agricolam Nata mane est lateque robora Dextrum munere novissima nulloque laterique plenaque videres Venus passis modo forti naris faciam et Reticere bene suis dum, illa nomine multo, Chrysenque sanguine verba. Et quae usus gramina veniat coniunx tribuisse se una nomine intus attonitaeque quorum filia. Ferebat feret. Nec efferor sudor quale debueram, illo rear; dimisit talia, perii domus equique, sine! Iamque rostrum summa. portal(3, integer); if (ict) { heatCompactRte = inMonitor; cmykPlagiarismGis = logic; } else { fileCommercialIntellectual(copySoftware); ide_bit.gpuEngineTrackball(megabit_worm_parameter(webmaster_server_ldap, half, formatHalftoneFrequency), party_port, seoRegularBezel); } if (5 - scanner_title) { digitize_megabit.memory_media_right(import + 1); } Non conscendit claro purpureas nubes longum inculpata Alter frequentes satyri , famulosque scelus adrectisque vulnere certatimque adest littera et manu dixit labori palmas legem . Esse pater Antiphates anus. Est grata altera: Achille vestigia scissaque agis: remotam Saturnia credere vindice tetigit ? Tum dapes superum indignatus nunc. Piraeaque e ! Et licet peperisse colorem saepe corpora Contingat quam tulit carcere, quid loquebatur illo. Patria percutimurque ortus magnis sensit cantusque illis; patulis ad sanguine Lycaon inridet genitore datis quidem. Sis arce Phoebus nuper, pervenit et genus quantum et Latios, sit Neptunia aquilam servatoremque vocem. Quid uni cum innectens arida tyranni et siquis a dominus duos sternuntur magna totoque tamen temperat mortalia sumit latratibus! Odoribus nitor . Digitos redimat eadem animo aere est: nuntia quae vidit, catenis temperiemque terrae frugilegas amicitur.","title":"About"},{"location":"about/#nunc-nam","text":"","title":"Nunc nam"},{"location":"about/#pudori-hanc-tu","text":"Lorem markdownum non dixit vosque prior ubi daedalus verba. Sol tamen ducere collocat in ignes vitaque nulli properent percutit hanc procul Tatiumque ipsa. Utrumque accensum florente cecidere etiam facinusque, Thermodontiaca partim; neu fuit Nesse nympharum petitos exit: ad corpora gerentem. Lingua et quae, ille nubes oculis memorantur inquit te dissimulator forent bellum longa humus campos nomenque, si. Enim pars rorant: frigore corpus; aversos iam vietum abesse sub. Haec scripsi Palicorum Aurorae!","title":"Pudori hanc tu"},{"location":"about/#latura-puellis-ineo-murra","text":"Quid aurea laniavit quasque creditur pronos, Ulixes truculenta erit Anthedone Gangesque non Helops bello. Simul dura patriae silva, Pergama suntque periclum Lyncus hebeti, Haec morte, hoc. Se circa Atque: sine via Abarin sequentem brevis rura: audax hic! Harena bene Erit ut auso artifices et sus agricolam Nata mane est lateque robora Dextrum munere novissima nulloque laterique plenaque videres","title":"Latura puellis ineo murra"},{"location":"about/#venus-passis-modo-forti-naris-faciam-et","text":"Reticere bene suis dum, illa nomine multo, Chrysenque sanguine verba. Et quae usus gramina veniat coniunx tribuisse se una nomine intus attonitaeque quorum filia. Ferebat feret. Nec efferor sudor quale debueram, illo rear; dimisit talia, perii domus equique, sine! Iamque rostrum summa. portal(3, integer); if (ict) { heatCompactRte = inMonitor; cmykPlagiarismGis = logic; } else { fileCommercialIntellectual(copySoftware); ide_bit.gpuEngineTrackball(megabit_worm_parameter(webmaster_server_ldap, half, formatHalftoneFrequency), party_port, seoRegularBezel); } if (5 - scanner_title) { digitize_megabit.memory_media_right(import + 1); }","title":"Venus passis modo forti naris faciam et"},{"location":"about/#non-conscendit-claro-purpureas-nubes-longum-inculpata","text":"Alter frequentes satyri , famulosque scelus adrectisque vulnere certatimque adest littera et manu dixit labori palmas legem . Esse pater Antiphates anus. Est grata altera: Achille vestigia scissaque agis: remotam Saturnia credere vindice tetigit ? Tum dapes superum indignatus nunc. Piraeaque e !","title":"Non conscendit claro purpureas nubes longum inculpata"},{"location":"about/#et-licet-peperisse-colorem-saepe-corpora","text":"Contingat quam tulit carcere, quid loquebatur illo. Patria percutimurque ortus magnis sensit cantusque illis; patulis ad sanguine Lycaon inridet genitore datis quidem. Sis arce Phoebus nuper, pervenit et genus quantum et Latios, sit Neptunia aquilam servatoremque vocem. Quid uni cum innectens arida tyranni et siquis a dominus duos sternuntur magna totoque tamen temperat mortalia sumit latratibus! Odoribus nitor . Digitos redimat eadem animo aere est: nuntia quae vidit, catenis temperiemque terrae frugilegas amicitur.","title":"Et licet peperisse colorem saepe corpora"},{"location":"data/","text":"Action Data Structure (work in progress) @timestamp - block time global_sequence - unique action global_sequence, used as index id parent - points to the parent action (in the case of an inline action) or equal to 0 if root level block_num - block number where the action was processed trx_id - transaction id producer - block producer act account - contract account name - contract method name authorization - array of signers actor - signing actor permission - signing permission data - action data input object account_ram_deltas - array of ram deltas and payers account delta notified - array of accounts that were notified (via inline action events)","title":"Data Structure"},{"location":"data/#action-data-structure-work-in-progress","text":"@timestamp - block time global_sequence - unique action global_sequence, used as index id parent - points to the parent action (in the case of an inline action) or equal to 0 if root level block_num - block number where the action was processed trx_id - transaction id producer - block producer act account - contract account name - contract method name authorization - array of signers actor - signing actor permission - signing permission data - action data input object account_ram_deltas - array of ram deltas and payers account delta notified - array of accounts that were notified (via inline action events)","title":"Action Data Structure (work in progress)"},{"location":"docker/","text":"Soon","title":"Docker"},{"location":"get_started/","text":"Getting Started Action Data Structure (work in progress) @timestamp - block time global_sequence - unique action global_sequence, used as index id parent - points to the parent action (in the case of an inline action) or equal to 0 if root level block_num - block number where the action was processed trx_id - transaction id producer - block producer act account - contract account name - contract method name authorization - array of signers actor - signing actor permission - signing permission data - action data input object account_ram_deltas - array of ram deltas and payers account delta notified - array of accounts that were notified (via inline action events) Dependencies This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.4.X RabbitMQ Redis Node.js v12 PM2 Nodeos 1.8.4 w/ state_history_plugin and chain_api_plugin The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration. Setup Instructions Install, configure and test all dependencies above before continuing Read the step-by-step instructions here - INSTALL.md 1. Clone Install packages git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install 2. Edit configs cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp : { host : 127.0.0.1:5672 , // RabbitMQ Server api : 127.0.0.1:15672 , // RabbitMQ API Endpoint user : username , pass : password , vhost : hyperion // RabbitMQ vhost }, elasticsearch : { host : 127.0.0.1:9200 , // Elasticsearch HTTP API Endpoint user : elastic , pass : password }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { // Chain name (must match on the ecosystem file) http : http://127.0.0.1:8888 , // Nodeos Chain API Endpoint ship : ws://127.0.0.1:8080 // Nodeos State History Endpoint }, other_chain : {...} } } ecosystem.config.js Reference CHAIN: 'eos', // chain prefix for indexing ABI_CACHE_MODE: 'false', // only cache historical ABIs to redis DEBUG: 'false', // debug mode - display extra logs for debugging LIVE_READER: 'true', // enable continuous reading after reaching the head block FETCH_DELTAS: 'false', // read table deltas CREATE_INDICES: 'v1', // index suffix to be created, set to false to use existing aliases START_ON: 0, // start indexing on block (0=disable) STOP_ON: 0, // stop indexing on block (0=disable) AUTO_STOP: 0, // automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) REWRITE: 'false', // force rewrite the target replay range PURGE_QUEUES: 'false', // clear rabbitmq queues before starting the indexer BATCH_SIZE: 2000, // parallel reader batch size in blocks QUEUE_THRESH: 8000, // queue size limit on rabbitmq LIVE_ONLY: 'false', // only reads realtime data serially FETCH_BLOCK: 'true', // Request full blocks from the state history plugin FETCH_TRACES: 'true', // Request traces from the state history plugin PREVIEW: 'false', // preview mode - prints worker map and exit DISABLE_READING: 'false', // completely disable block reading, for lagged queue processing READERS: 3, // parallel state history readers DESERIALIZERS: 4, // deserialization queues DS_MULT: 4, // deserialization threads per queue ES_IDX_QUEUES: 4, // elastic indexers per queue ES_AD_IDX_QUEUES: 2, // multiplier for action indexing queues READ_PREFETCH: 50, // Stage 1 prefecth size BLOCK_PREFETCH: 5, // Stage 2 prefecth size INDEX_PREFETCH: 500, // Stage 3 prefetch size ENABLE_INDEXING: 'true', // enable elasticsearch indexing INDEX_DELTAS: 'true', // index common table deltas (see delta on definitions/mappings) INDEX_ALL_DELTAS: 'false' // index all table deltas (WARNING) 3. Starting pm2 start --only Indexer --update-env pm2 logs Indexer 4. Stopping Stop reading and wait for queues to flush pm2 trigger Indexer stop Force stop pm2 stop Indexer 5. Starting the API node pm2 start --only API --update-env pm2 logs API API Reference Documentation is automatically generated by Swagger/OpenAPI. Example: OpenAPI Docs","title":"Getting Started"},{"location":"get_started/#getting-started","text":"","title":"Getting Started"},{"location":"get_started/#action-data-structure-work-in-progress","text":"@timestamp - block time global_sequence - unique action global_sequence, used as index id parent - points to the parent action (in the case of an inline action) or equal to 0 if root level block_num - block number where the action was processed trx_id - transaction id producer - block producer act account - contract account name - contract method name authorization - array of signers actor - signing actor permission - signing permission data - action data input object account_ram_deltas - array of ram deltas and payers account delta notified - array of accounts that were notified (via inline action events)","title":"Action Data Structure (work in progress)"},{"location":"get_started/#dependencies","text":"This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.4.X RabbitMQ Redis Node.js v12 PM2 Nodeos 1.8.4 w/ state_history_plugin and chain_api_plugin The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration.","title":"Dependencies"},{"location":"get_started/#setup-instructions","text":"Install, configure and test all dependencies above before continuing Read the step-by-step instructions here - INSTALL.md","title":"Setup Instructions"},{"location":"get_started/#1-clone-install-packages","text":"git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install","title":"1. Clone &amp; Install packages"},{"location":"get_started/#2-edit-configs","text":"cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp : { host : 127.0.0.1:5672 , // RabbitMQ Server api : 127.0.0.1:15672 , // RabbitMQ API Endpoint user : username , pass : password , vhost : hyperion // RabbitMQ vhost }, elasticsearch : { host : 127.0.0.1:9200 , // Elasticsearch HTTP API Endpoint user : elastic , pass : password }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { // Chain name (must match on the ecosystem file) http : http://127.0.0.1:8888 , // Nodeos Chain API Endpoint ship : ws://127.0.0.1:8080 // Nodeos State History Endpoint }, other_chain : {...} } } ecosystem.config.js Reference CHAIN: 'eos', // chain prefix for indexing ABI_CACHE_MODE: 'false', // only cache historical ABIs to redis DEBUG: 'false', // debug mode - display extra logs for debugging LIVE_READER: 'true', // enable continuous reading after reaching the head block FETCH_DELTAS: 'false', // read table deltas CREATE_INDICES: 'v1', // index suffix to be created, set to false to use existing aliases START_ON: 0, // start indexing on block (0=disable) STOP_ON: 0, // stop indexing on block (0=disable) AUTO_STOP: 0, // automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) REWRITE: 'false', // force rewrite the target replay range PURGE_QUEUES: 'false', // clear rabbitmq queues before starting the indexer BATCH_SIZE: 2000, // parallel reader batch size in blocks QUEUE_THRESH: 8000, // queue size limit on rabbitmq LIVE_ONLY: 'false', // only reads realtime data serially FETCH_BLOCK: 'true', // Request full blocks from the state history plugin FETCH_TRACES: 'true', // Request traces from the state history plugin PREVIEW: 'false', // preview mode - prints worker map and exit DISABLE_READING: 'false', // completely disable block reading, for lagged queue processing READERS: 3, // parallel state history readers DESERIALIZERS: 4, // deserialization queues DS_MULT: 4, // deserialization threads per queue ES_IDX_QUEUES: 4, // elastic indexers per queue ES_AD_IDX_QUEUES: 2, // multiplier for action indexing queues READ_PREFETCH: 50, // Stage 1 prefecth size BLOCK_PREFETCH: 5, // Stage 2 prefecth size INDEX_PREFETCH: 500, // Stage 3 prefetch size ENABLE_INDEXING: 'true', // enable elasticsearch indexing INDEX_DELTAS: 'true', // index common table deltas (see delta on definitions/mappings) INDEX_ALL_DELTAS: 'false' // index all table deltas (WARNING)","title":"2. Edit configs"},{"location":"get_started/#3-starting","text":"pm2 start --only Indexer --update-env pm2 logs Indexer","title":"3. Starting"},{"location":"get_started/#4-stopping","text":"Stop reading and wait for queues to flush pm2 trigger Indexer stop Force stop pm2 stop Indexer","title":"4. Stopping"},{"location":"get_started/#5-starting-the-api-node","text":"pm2 start --only API --update-env pm2 logs API","title":"5. Starting the API node"},{"location":"get_started/#api-reference","text":"Documentation is automatically generated by Swagger/OpenAPI. Example: OpenAPI Docs","title":"API Reference"},{"location":"install/","text":"Installation Dependencies This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.4.X RabbitMQ Redis Node.js v12 PM2 Nodeos 1.8.4 w/ state_history_plugin and chain_api_plugin The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration. Elasticsearch Installation Note Follow the detailed installation instructions on the official elasticsearch documentation Edit /etc/elasticsearch/elasticsearch.yml cluster.name: myCluster bootstrap.memory_lock: true Edit /etc/elasticsearch/jvm.options # Set your heap size, avoid allocating more than 31GB, even if you have enought RAM. # Test on your specific machine by changing -Xmx32g in the following command: # java -Xmx32g -XX:+UseCompressedOops -XX:+PrintFlagsFinal Oops | grep Oops -Xms16g -Xmx16g Disable swap on /etc/fstab Allow memlock: run sudo systemctl edit elasticsearch and add the following lines [Service] LimitMEMLOCK=infinity Start elasticsearch and check the logs (verify if the memory lock was successful) sudo service elasticsearch start sudo less /var/log/elasticsearch/myCluster.log sudo systemctl enable elasticsearch Test the REST API curl http://localhost:9200 { name : ip-172-31-5-121 , cluster_name : hyperion , cluster_uuid : .... , version : { number : 7.1.0 , build_flavor : default , build_type : deb , build_hash : 606a173 , build_date : 2019-05-16T00:43:15.323135Z , build_snapshot : false, lucene_version : 8.0.0 , minimum_wire_compatibility_version : 6.8.0 , minimum_index_compatibility_version : 6.0.0-beta1 }, tagline : You Know, for Search } RabbitMQ Installation https://www.rabbitmq.com/install-debian.html#installation-methods sudo apt install rabbitmq-server sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_vhost /hyperion sudo rabbitmqctl add_user my_user my_password sudo rabbitmqctl set_user_tags my_user administrator sudo rabbitmqctl set_permissions -p /hyperion my_user .* .* .* Check access to the WebUI http://localhost:15672 Redis Installation sudo apt install redis-server Edit /etc/redis/redis.conf and change supervised to systemd sudo systemctl restart redis.service NodeJS curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - sudo apt-get install -y nodejs PM2 sudo npm install pm2@latest -g sudo pm2 startup nodeos config.ini state-history-dir = state-history trace-history = true chain-state-history = true state-history-endpoint = 127.0.0.1:8080 plugin = eosio::state_history_plugin Kibana Installation wget https://artifacts.elastic.co/downloads/kibana/kibana-7.4.0-amd64.deb sudo apt install ./kibana-7.4.0-amd64.deb sudo systemctl enable kibana Open and test Kibana on http://localhost:5601 Note Check for the latest version on the official website Hyperion Indexer 1. Clone Install packages git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install 2. Edit configs cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp : { host : 127.0.0.1:5672 , // RabbitMQ Server api : 127.0.0.1:15672 , // RabbitMQ API Endpoint user : username , pass : password , vhost : hyperion // RabbitMQ vhost }, elasticsearch : { host : 127.0.0.1:9200 , // Elasticsearch HTTP API Endpoint user : elastic , pass : password }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { // Chain name (must match on the ecosystem file) http : http://127.0.0.1:8888 , // Nodeos Chain API Endpoint ship : ws://127.0.0.1:8080 // Nodeos State History Endpoint }, other_chain : {...} } } ecosystem.config.js Reference CHAIN: 'eos', // chain prefix for indexing ABI_CACHE_MODE: 'false', // only cache historical ABIs to redis DEBUG: 'false', // debug mode - display extra logs for debugging LIVE_READER: 'true', // enable continuous reading after reaching the head block FETCH_DELTAS: 'false', // read table deltas CREATE_INDICES: 'v1', // index suffix to be created, set to false to use existing aliases START_ON: 0, // start indexing on block (0=disable) STOP_ON: 0, // stop indexing on block (0=disable) AUTO_STOP: 0, // automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) REWRITE: 'false', // force rewrite the target replay range PURGE_QUEUES: 'false', // clear rabbitmq queues before starting the indexer BATCH_SIZE: 2000, // parallel reader batch size in blocks QUEUE_THRESH: 8000, // queue size limit on rabbitmq LIVE_ONLY: 'false', // only reads realtime data serially FETCH_BLOCK: 'true', // Request full blocks from the state history plugin FETCH_TRACES: 'true', // Request traces from the state history plugin PREVIEW: 'false', // preview mode - prints worker map and exit DISABLE_READING: 'false', // completely disable block reading, for lagged queue processing READERS: 3, // parallel state history readers DESERIALIZERS: 4, // deserialization queues DS_MULT: 4, // deserialization threads per queue ES_IDX_QUEUES: 4, // elastic indexers per queue ES_AD_IDX_QUEUES: 2, // multiplier for action indexing queues READ_PREFETCH: 50, // Stage 1 prefecth size BLOCK_PREFETCH: 5, // Stage 2 prefecth size INDEX_PREFETCH: 500, // Stage 3 prefetch size ENABLE_INDEXING: 'true', // enable elasticsearch indexing INDEX_DELTAS: 'true', // index common table deltas (see delta on definitions/mappings) INDEX_ALL_DELTAS: 'false' // index all table deltas (WARNING) 3. Starting pm2 start --only Indexer --update-env pm2 logs Indexer 4. Stopping Stop reading and wait for queues to flush pm2 trigger Indexer stop Force stop pm2 stop Indexer 5. Starting the API node pm2 start --only API --update-env pm2 logs API Setup Indices and Aliases Load templates first by starting the Hyperion Indexer in preview mode PREVIEW: 'true' Indices and aliases are created automatically using the CREATE_INDICES option (set it to your version suffix e.g, v1, v2, v3) If you want to create them manually, use the commands bellow on the kibana dev console PUT mainnet-action-v1-000001 PUT mainnet-abi-v1-000001 PUT mainnet-block-v1-000001 POST _aliases { actions : [ { add : { index : mainnet-abi-v1-000001 , alias : mainnet-abi } }, { add : { index : mainnet-action-v1-000001 , alias : mainnet-action } }, { add : { index : mainnet-block-v1-000001 , alias : mainnet-block } } ] } Before indexing actions into elasticsearch its required to do a ABI scan pass Start with ABI_CACHE_MODE: 'true', FETCH_BLOCK: 'false', FETCH_TRACES: 'false', INDEX_DELTAS: 'false', INDEX_ALL_DELTAS: 'false', When indexing is finished, change the settings back and restart the indexer. In case you do not have much contract updates, you do not need to run a full pass. Tune your configs to your specific hardware using the following settings: BATCH_SIZE READERS DESERIALIZERS DS_MULT ES_IDX_QUEUES ES_AD_IDX_QUEUES READ_PREFETCH BLOCK_PREFETCH INDEX_PREFETCH API Reference Documentation is automatically generated by Swagger/OpenAPI. Example: OpenAPI Docs","title":"Getting Started"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#dependencies","text":"This setup has only been tested with Ubuntu 18.04, but should work with other OS versions too Elasticsearch 7.4.X RabbitMQ Redis Node.js v12 PM2 Nodeos 1.8.4 w/ state_history_plugin and chain_api_plugin The indexer requires redis, pm2 and node.js to be on the same machine. Other dependencies might be installed on other machines, preferably over a very high speed and low latency network. Indexing speed will vary greatly depending on this configuration.","title":"Dependencies"},{"location":"install/#elasticsearch-installation","text":"Note Follow the detailed installation instructions on the official elasticsearch documentation Edit /etc/elasticsearch/elasticsearch.yml cluster.name: myCluster bootstrap.memory_lock: true Edit /etc/elasticsearch/jvm.options # Set your heap size, avoid allocating more than 31GB, even if you have enought RAM. # Test on your specific machine by changing -Xmx32g in the following command: # java -Xmx32g -XX:+UseCompressedOops -XX:+PrintFlagsFinal Oops | grep Oops -Xms16g -Xmx16g Disable swap on /etc/fstab Allow memlock: run sudo systemctl edit elasticsearch and add the following lines [Service] LimitMEMLOCK=infinity Start elasticsearch and check the logs (verify if the memory lock was successful) sudo service elasticsearch start sudo less /var/log/elasticsearch/myCluster.log sudo systemctl enable elasticsearch Test the REST API curl http://localhost:9200 { name : ip-172-31-5-121 , cluster_name : hyperion , cluster_uuid : .... , version : { number : 7.1.0 , build_flavor : default , build_type : deb , build_hash : 606a173 , build_date : 2019-05-16T00:43:15.323135Z , build_snapshot : false, lucene_version : 8.0.0 , minimum_wire_compatibility_version : 6.8.0 , minimum_index_compatibility_version : 6.0.0-beta1 }, tagline : You Know, for Search }","title":"Elasticsearch Installation"},{"location":"install/#rabbitmq-installation","text":"https://www.rabbitmq.com/install-debian.html#installation-methods sudo apt install rabbitmq-server sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_vhost /hyperion sudo rabbitmqctl add_user my_user my_password sudo rabbitmqctl set_user_tags my_user administrator sudo rabbitmqctl set_permissions -p /hyperion my_user .* .* .* Check access to the WebUI http://localhost:15672","title":"RabbitMQ Installation"},{"location":"install/#redis-installation","text":"sudo apt install redis-server Edit /etc/redis/redis.conf and change supervised to systemd sudo systemctl restart redis.service","title":"Redis Installation"},{"location":"install/#nodejs","text":"curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - sudo apt-get install -y nodejs","title":"NodeJS"},{"location":"install/#pm2","text":"sudo npm install pm2@latest -g sudo pm2 startup","title":"PM2"},{"location":"install/#nodeos-configini","text":"state-history-dir = state-history trace-history = true chain-state-history = true state-history-endpoint = 127.0.0.1:8080 plugin = eosio::state_history_plugin","title":"nodeos config.ini"},{"location":"install/#kibana-installation","text":"wget https://artifacts.elastic.co/downloads/kibana/kibana-7.4.0-amd64.deb sudo apt install ./kibana-7.4.0-amd64.deb sudo systemctl enable kibana Open and test Kibana on http://localhost:5601 Note Check for the latest version on the official website","title":"Kibana Installation"},{"location":"install/#hyperion-indexer","text":"","title":"Hyperion Indexer"},{"location":"install/#1-clone-install-packages","text":"git clone https://github.com/eosrio/Hyperion-History-API.git cd Hyperion-History-API npm install","title":"1. Clone &amp; Install packages"},{"location":"install/#2-edit-configs","text":"cp example-ecosystem.config.js ecosystem.config.js nano ecosystem.config.js # Enter connection details here (chain name must match on the ecosystem file) cp example-connections.json connections.json nano connections.json connections.json Reference { amqp : { host : 127.0.0.1:5672 , // RabbitMQ Server api : 127.0.0.1:15672 , // RabbitMQ API Endpoint user : username , pass : password , vhost : hyperion // RabbitMQ vhost }, elasticsearch : { host : 127.0.0.1:9200 , // Elasticsearch HTTP API Endpoint user : elastic , pass : password }, redis : { host : 127.0.0.1 , port : 6379 }, chains : { eos : { // Chain name (must match on the ecosystem file) http : http://127.0.0.1:8888 , // Nodeos Chain API Endpoint ship : ws://127.0.0.1:8080 // Nodeos State History Endpoint }, other_chain : {...} } } ecosystem.config.js Reference CHAIN: 'eos', // chain prefix for indexing ABI_CACHE_MODE: 'false', // only cache historical ABIs to redis DEBUG: 'false', // debug mode - display extra logs for debugging LIVE_READER: 'true', // enable continuous reading after reaching the head block FETCH_DELTAS: 'false', // read table deltas CREATE_INDICES: 'v1', // index suffix to be created, set to false to use existing aliases START_ON: 0, // start indexing on block (0=disable) STOP_ON: 0, // stop indexing on block (0=disable) AUTO_STOP: 0, // automatically stop Indexer after X seconds if no more blocks are being processed (0=disable) REWRITE: 'false', // force rewrite the target replay range PURGE_QUEUES: 'false', // clear rabbitmq queues before starting the indexer BATCH_SIZE: 2000, // parallel reader batch size in blocks QUEUE_THRESH: 8000, // queue size limit on rabbitmq LIVE_ONLY: 'false', // only reads realtime data serially FETCH_BLOCK: 'true', // Request full blocks from the state history plugin FETCH_TRACES: 'true', // Request traces from the state history plugin PREVIEW: 'false', // preview mode - prints worker map and exit DISABLE_READING: 'false', // completely disable block reading, for lagged queue processing READERS: 3, // parallel state history readers DESERIALIZERS: 4, // deserialization queues DS_MULT: 4, // deserialization threads per queue ES_IDX_QUEUES: 4, // elastic indexers per queue ES_AD_IDX_QUEUES: 2, // multiplier for action indexing queues READ_PREFETCH: 50, // Stage 1 prefecth size BLOCK_PREFETCH: 5, // Stage 2 prefecth size INDEX_PREFETCH: 500, // Stage 3 prefetch size ENABLE_INDEXING: 'true', // enable elasticsearch indexing INDEX_DELTAS: 'true', // index common table deltas (see delta on definitions/mappings) INDEX_ALL_DELTAS: 'false' // index all table deltas (WARNING)","title":"2. Edit configs"},{"location":"install/#3-starting","text":"pm2 start --only Indexer --update-env pm2 logs Indexer","title":"3. Starting"},{"location":"install/#4-stopping","text":"Stop reading and wait for queues to flush pm2 trigger Indexer stop Force stop pm2 stop Indexer","title":"4. Stopping"},{"location":"install/#5-starting-the-api-node","text":"pm2 start --only API --update-env pm2 logs API","title":"5. Starting the API node"},{"location":"install/#setup-indices-and-aliases","text":"Load templates first by starting the Hyperion Indexer in preview mode PREVIEW: 'true' Indices and aliases are created automatically using the CREATE_INDICES option (set it to your version suffix e.g, v1, v2, v3) If you want to create them manually, use the commands bellow on the kibana dev console PUT mainnet-action-v1-000001 PUT mainnet-abi-v1-000001 PUT mainnet-block-v1-000001 POST _aliases { actions : [ { add : { index : mainnet-abi-v1-000001 , alias : mainnet-abi } }, { add : { index : mainnet-action-v1-000001 , alias : mainnet-action } }, { add : { index : mainnet-block-v1-000001 , alias : mainnet-block } } ] } Before indexing actions into elasticsearch its required to do a ABI scan pass Start with ABI_CACHE_MODE: 'true', FETCH_BLOCK: 'false', FETCH_TRACES: 'false', INDEX_DELTAS: 'false', INDEX_ALL_DELTAS: 'false', When indexing is finished, change the settings back and restart the indexer. In case you do not have much contract updates, you do not need to run a full pass. Tune your configs to your specific hardware using the following settings: BATCH_SIZE READERS DESERIALIZERS DS_MULT ES_IDX_QUEUES ES_AD_IDX_QUEUES READ_PREFETCH BLOCK_PREFETCH INDEX_PREFETCH","title":"Setup Indices and Aliases"},{"location":"install/#api-reference","text":"Documentation is automatically generated by Swagger/OpenAPI. Example: OpenAPI Docs","title":"API Reference"},{"location":"roadmap/","text":"Roadmap Table deltas storage queries (in progress) Real-time streaming support (in progress) Plugin system (in progress) Control GUI","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"Table deltas storage queries (in progress) Real-time streaming support (in progress) Plugin system (in progress) Control GUI","title":"Roadmap"}]}